#!/bin/bash

# üöÄ Ativa o ambiente Conda (ajuste o caminho para o seu conda.sh se necess√°rio)
conda activate hat-env

# ‚úÖ Clona o reposit√≥rio (se ainda n√£o existir)
if [ ! -d "HAT" ]; then
    git clone https://github.com/XPixelGroup/HAT.git
fi
cd HAT

# üì¶ Instala depend√™ncias
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
pip install basicsr==1.3.4.9
pip install -r requirements.txt
python setup.py develop

# ‚úÖ Instala gdown se necess√°rio
pip install gdown

# üì• Baixa o modelo do Google Drive
MODEL_ID="1BGo-vYVpcn41kQ6fuFU6u3vlc2LrcnXi"
MODEL_PATH="experiments/pretrained_models/Real_HAT_GAN_sharper.pth"
mkdir -p experiments/pretrained_models
if [ ! -f "$MODEL_PATH" ]; then
    echo "üîΩ Baixando modelo Real_HAT_GAN_sharper.pth do Google Drive..."
    gdown "https://drive.google.com/uc?id=$MODEL_ID" -O "$MODEL_PATH"
else
    echo "‚úÖ Modelo j√° existe em $MODEL_PATH"
fi

# ‚ö†Ô∏è Corrige o import quebrado do torchvision
#sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' basicsr/data/degradations.py

sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /home/davi/.conda/envs/hat-env/lib/python3.10/site-packages/basicsr/data/degradations.py

# Passo 4: Criar a pasta 'images_teste'
mkdir -p ./inputs_imgs

# Passo 5: Baixar a imagem de teste do Google Drive e mov√™-la para a pasta 'images_teste'
gdown https://drive.google.com/uc?id=1B4Qafq44qYE1G838DW4TnjirIztFBEbb -O ./inputs_imgs/test_image.png

# üìÅ Cria op√ß√µes de teste
mkdir -p options/test

# üìÑ Cria o arquivo de configura√ß√£o YAML
cat <<EOF > options/test/Real_HAT_GAN_sharper.pth.yml
name: Real_HAT_GAN_sharper.pth
model_type: HATModel
scale: 4
num_gpu: 1

datasets:
  test:
    name: demo
    type: SingleImageDataset
    dataroot_lq: ./inputs_imgs
    io_backend:
      type: disk

network_g:
  type: HAT
  upscale: 4
  in_chans: 3
  img_size: 64
  window_size: 16
  depths: [6, 6, 6, 6, 6, 6]
  embed_dim: 180
  num_heads: [6, 6, 6, 6, 6, 6]
  mlp_ratio: 2
  upsampler: 'pixelshuffle'
  resi_connection: '1conv'

path:
  pretrain_network_g: experiments/pretrained_models/Real_HAT_GAN_sharper.pth
  param_key_g: params_ema
  strict_load_g: true
  resume_state: ~

val:
  save_img: true
  suffix: ~
  flip: false
  x4: true
EOF

# üßπ Limpa resultados anteriores
rm -rf results/Real_HAT_GAN_sharper*

# üöÄ Executa o teste
python hat/test.py -opt options/test/Real_HAT_GAN_sharper.pth.yml

# ‚úÖ Mostra os arquivos de sa√≠da
echo "‚úÖ Resultados salvos em: results/Real_HAT_GAN_sharper/visual/"
ls -lh results/Real_HAT_GAN_sharper/visual/
